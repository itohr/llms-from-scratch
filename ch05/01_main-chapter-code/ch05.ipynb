{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b071913",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on Unlabeled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3671c",
   "metadata": {},
   "source": [
    "## 5.1 Evaluation generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff61de",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0978b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f652a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text: str, tokenizer: tiktoken.Encoding) -> torch.Tensor:\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids: torch.Tensor, tokenizer: tiktoken.Encoding) -> str:\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befba4e5",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8b7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], [40, 1107, 588]])\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345], [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8f7f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1069fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed937e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45230384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d422754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d56fbbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a22890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2724fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30395cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits flat shape: torch.Size([6, 50257])\n",
      "Targets flat shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Logits flat shape:\", logits_flat.shape)\n",
    "print(\"Targets flat shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76aeaded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8021d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b6ee5",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89f72cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61e6cb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "137817e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faeab429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc4eacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf0b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the training loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"increase the `training_ratio`\"\n",
    "    )\n",
    "\n",
    "if total_tokens * (1 - train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the validation loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"decrease the `training_ratio`\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83063531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokens: 4608\n",
      "Validation tokens: 512\n",
      "Total tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Train tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"Total tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def calc_loss_batch(\n",
    "    input_batch: torch.Tensor,\n",
    "    target_batch: torch.Tensor,\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(\n",
    "    data_loader: DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    num_batches: int | None = None,\n",
    ") -> float:\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68f09a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.987583372328016\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "print(f\"Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa20fa",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ece1ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model: GPTModel,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: int,\n",
    "    eval_iter: int,\n",
    "    start_context: str,\n",
    "    tokenizer: tiktoken.Encoding,\n",
    ") -> tuple[list[float], list[float], list[int]]:\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: GPTModel,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    ") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(\n",
    "    model: GPTModel,\n",
    "    tokenizer: tiktoken.Encoding,\n",
    "    device: torch.device,\n",
    "    start_context: str,\n",
    ") -> None:\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size,\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e41d9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.932\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.621, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.601\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.584, Val loss 6.480\n",
      "Ep 3 (Step 000025): Train loss 5.538, Val loss 6.407\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.142, Val loss 6.365\n",
      "Ep 4 (Step 000035): Train loss 4.982, Val loss 6.382\n",
      "Every effort moves you a a, and a a, and a-- the picture. Gisburn, and a was, and a. I had been. of the of the of the of the a of the of the of the of the of the of the of\n",
      "Ep 5 (Step 000040): Train loss 4.342, Val loss 6.248\n",
      "Every effort moves you, I had been the picture, I had to the picture. \"Oh, in the picture, in the fact of the picture to me.  \"I had been.  \"Oh, I had been the room, in the\n",
      "Ep 6 (Step 000045): Train loss 4.007, Val loss 6.209\n",
      "Ep 6 (Step 000050): Train loss 3.521, Val loss 6.170\n",
      "Every effort moves you know the                                                \n",
      "Ep 7 (Step 000055): Train loss 3.553, Val loss 6.187\n",
      "Ep 7 (Step 000060): Train loss 2.740, Val loss 6.153\n",
      "Every effort moves you know he was to have to the Riviera, I was a little of a.           \"I didn't I was to the donkey.            \n",
      "Ep 8 (Step 000065): Train loss 2.299, Val loss 6.141\n",
      "Ep 8 (Step 000070): Train loss 1.955, Val loss 6.201\n",
      "Every effort moves you know,\" was not that the picture. Gisburn--as such--had not to have to see it the fact, as he had a smile behind his painting.  \"--and it, the donkey. \"There were days, in\n",
      "Ep 9 (Step 000075): Train loss 1.585, Val loss 6.229\n",
      "Ep 9 (Step 000080): Train loss 1.251, Val loss 6.271\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I felt to have given Miss Croft the fact, the cigars you like.\"  \"Oh, and his pictures--the quality of Jack's \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.961, Val loss 6.305\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"    \"Oh, and back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, token_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91104b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(\n",
    "    epochs_seen: torch.Tensor,\n",
    "    tokens_seen: list[int],\n",
    "    train_losses: list[float],\n",
    "    val_losses: list[float],\n",
    "):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fdb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
